{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "import re\n",
    "from readprocess import readprocess\n",
    "from NNfunctionality import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_path = Path(Path.cwd(),\"..\",\"ProcessedHistograms\").resolve()\n",
    "yield_path = Path(Path.cwd(),\"Data\",\"Yield Data\",\"Crop_Yields.csv\").resolve()\n",
    "data_class = readprocess(featurepath=hist_path,yieldpath=yield_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(data_class.final_dataset,data_class.yield_dict['Kenya'])\n",
    "train_loader = DataLoader(dataset,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pasindu.Samaranayake\\Desktop\\MSc\\MSBD 5001\\EarthEngine\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.75 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "epoch_no = 10\n",
    "num_hidden_units = 100\n",
    "num_features = 576 #64 bins * 9 bands per image in each time step\n",
    "batch_size = 1\n",
    "trainvalidate = TrainingValidatingLSTM()\n",
    "model = LSTMnetwork(576,num_hidden_units)\n",
    "mse_loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.001)\n",
    "for i in range(epoch_no):\n",
    "    trainvalidate.train(dataloader=train_loader,model=model,loss_fn=mse_loss,optimizer = optimizer,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 29, 576])\n"
     ]
    }
   ],
   "source": [
    "result = list()\n",
    "ground = list()\n",
    "h = model.init_hidden(1)\n",
    "for batch,(X,y) in enumerate(train_loader):\n",
    "    print(X.shape)\n",
    "    break\n",
    "    # res,_ = model(X,h)\n",
    "    # result.append(float(res))\n",
    "    # ground.append(float(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.440000057220459,\n",
       " 8.34000015258789,\n",
       " 6.630000114440918,\n",
       " 8.180000305175781,\n",
       " 7.760000228881836,\n",
       " 6.360000133514404,\n",
       " 7.329999923706055,\n",
       " 5.579999923706055,\n",
       " 6.139999866485596,\n",
       " 8.010000228881836,\n",
       " 7.059999942779541,\n",
       " 6.929999828338623,\n",
       " 6.360000133514404]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer = nn.LSTM(576,100,num_layers = 1,dropout = 0.75,batch_first = True)\n",
    "dense_layer1 = nn.Linear(in_features=100,out_features=256,bias = True)\n",
    "dense_layer2 = nn.Linear(in_features=256,out_features=1,bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1220, -0.0533, -0.0012, -0.0084,  0.0326, -0.0050,  0.0467, -0.0647,\n",
      "         0.0825,  0.0339,  0.0589,  0.0801,  0.0063,  0.0733, -0.0119, -0.0060,\n",
      "        -0.0248, -0.0939,  0.0455,  0.0948, -0.0487, -0.0288, -0.0707, -0.0468,\n",
      "         0.0437,  0.0983, -0.1005, -0.0054, -0.0834, -0.0687, -0.0366, -0.0142,\n",
      "         0.0127,  0.0331, -0.0728, -0.0497, -0.0896, -0.0240,  0.0031, -0.0088,\n",
      "        -0.0376,  0.0331, -0.0342,  0.0043,  0.0258, -0.0658,  0.0717, -0.0260,\n",
      "         0.0961,  0.0197, -0.0242,  0.0475,  0.0299,  0.0102,  0.0482, -0.0811,\n",
      "         0.0866, -0.0542, -0.0331,  0.0113,  0.0539,  0.1102,  0.0736, -0.1080,\n",
      "        -0.0440, -0.0526, -0.0030,  0.1028,  0.0584,  0.0621, -0.0550,  0.0381,\n",
      "         0.0302,  0.0928, -0.1148,  0.0194, -0.0691, -0.0810, -0.0981, -0.1099,\n",
      "         0.1043, -0.1049,  0.0082,  0.0879,  0.0600,  0.0133, -0.0823,  0.0305,\n",
      "         0.0711,  0.0133, -0.0357,  0.0735, -0.0318, -0.0073, -0.0181,  0.0095,\n",
      "        -0.0983, -0.0368, -0.0154,  0.0387], grad_fn=<SelectBackward0>)\n",
      "tensor([-0.0439, -0.0275, -0.0926, -0.0210, -0.0430, -0.0795,  0.0251,  0.0579,\n",
      "        -0.0464, -0.0101, -0.0579,  0.1401, -0.0765, -0.1235, -0.0939, -0.0623,\n",
      "        -0.0699,  0.0483, -0.0405, -0.0241,  0.1040, -0.0178, -0.0610, -0.0892,\n",
      "         0.0665,  0.0282,  0.0051, -0.0040,  0.0485, -0.0423,  0.0054, -0.0362,\n",
      "        -0.0866, -0.0165,  0.0520,  0.1277,  0.0837, -0.0382,  0.0240,  0.0747,\n",
      "        -0.0177, -0.0604, -0.0682, -0.0025,  0.0394, -0.0457, -0.0565, -0.0189,\n",
      "        -0.1141,  0.0030, -0.0461,  0.0600,  0.0872,  0.0835, -0.0208, -0.0266,\n",
      "         0.0741, -0.0026, -0.0027, -0.0096, -0.0178,  0.0430,  0.0538,  0.0276,\n",
      "        -0.0455, -0.0503,  0.0193, -0.0785, -0.0216,  0.0813,  0.0636, -0.0363,\n",
      "        -0.0343,  0.1203, -0.0111,  0.1359, -0.1137, -0.0638, -0.1048, -0.0223,\n",
      "         0.0241, -0.0098, -0.0115, -0.0387,  0.1448, -0.0193, -0.0435,  0.0723,\n",
      "        -0.0304,  0.0041,  0.0167,  0.0979,  0.0296,  0.0473,  0.0130,  0.1626,\n",
      "         0.0888, -0.0198,  0.0363, -0.0036,  0.0389, -0.0272,  0.0447,  0.0756,\n",
      "        -0.1063, -0.0894,  0.1238, -0.0694,  0.0111, -0.0391, -0.0845, -0.0116,\n",
      "         0.0531,  0.0580,  0.0658, -0.0518, -0.1140,  0.0087,  0.0830,  0.0632,\n",
      "        -0.0115,  0.0693, -0.0273, -0.0076,  0.1041, -0.1063,  0.0336,  0.0666,\n",
      "        -0.0760,  0.1255, -0.1207, -0.1064,  0.0162,  0.0390,  0.0384,  0.0525,\n",
      "        -0.0407,  0.0564,  0.1148,  0.0523,  0.0730,  0.0358,  0.0419, -0.0236,\n",
      "        -0.0102, -0.0324,  0.1421, -0.0408,  0.0836, -0.0700,  0.1317,  0.0735,\n",
      "         0.0783,  0.1109, -0.0466, -0.0427, -0.0433, -0.0076,  0.0465, -0.0210,\n",
      "        -0.1829,  0.0051,  0.0353, -0.0328, -0.0413,  0.1404,  0.0893, -0.0248,\n",
      "         0.0965,  0.0183, -0.0412,  0.0040,  0.0770,  0.0560, -0.0390, -0.0933,\n",
      "        -0.0157,  0.0642, -0.0902, -0.0032, -0.0217,  0.0278,  0.0429, -0.0719,\n",
      "        -0.1175, -0.0330, -0.0987, -0.0236,  0.1420,  0.0692, -0.0430,  0.0810,\n",
      "         0.0510, -0.0760, -0.0574,  0.0899, -0.0492,  0.0138,  0.0057,  0.0936,\n",
      "         0.0180, -0.0359,  0.0958, -0.0797, -0.0428,  0.0403,  0.0622, -0.0004,\n",
      "         0.0754, -0.0460,  0.0226,  0.1110, -0.0913,  0.0105, -0.0201,  0.0440,\n",
      "         0.0552, -0.0658,  0.0187,  0.1274, -0.0027, -0.0813,  0.0616, -0.0627,\n",
      "        -0.0280, -0.1060, -0.0162, -0.0339,  0.0591, -0.0986,  0.1488,  0.1059,\n",
      "        -0.0185, -0.0010, -0.0315,  0.0784, -0.1152, -0.0218,  0.0822,  0.0301,\n",
      "        -0.1040,  0.0302,  0.0899, -0.0301, -0.0839, -0.0050, -0.0646,  0.0869,\n",
      "         0.0658,  0.0885,  0.0730,  0.0864, -0.0045,  0.0688, -0.0348,  0.0803],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([0.1413], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "h = model.init_hidden(1)\n",
    "for batch,(X,y) in enumerate(train_loader):\n",
    "    l,h = lstm_layer(X,h)\n",
    "    l = l.contiguous().view(-1,100)[-1]\n",
    "    print(l)\n",
    "    o1 = dense_layer1(l)\n",
    "    print(o1)\n",
    "    o2 = dense_layer2(o1)\n",
    "    print(o2)\n",
    "    # yield_val = model(X,h)\n",
    "    #print(yield_val)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1220, -0.0533, -0.0012, -0.0084,  0.0326, -0.0050,  0.0467,\n",
       "           -0.0647,  0.0825,  0.0339,  0.0589,  0.0801,  0.0063,  0.0733,\n",
       "           -0.0119, -0.0060, -0.0248, -0.0939,  0.0455,  0.0948, -0.0487,\n",
       "           -0.0288, -0.0707, -0.0468,  0.0437,  0.0983, -0.1005, -0.0054,\n",
       "           -0.0834, -0.0687, -0.0366, -0.0142,  0.0127,  0.0331, -0.0728,\n",
       "           -0.0497, -0.0896, -0.0240,  0.0031, -0.0088, -0.0376,  0.0331,\n",
       "           -0.0342,  0.0043,  0.0258, -0.0658,  0.0717, -0.0260,  0.0961,\n",
       "            0.0197, -0.0242,  0.0475,  0.0299,  0.0102,  0.0482, -0.0811,\n",
       "            0.0866, -0.0542, -0.0331,  0.0113,  0.0539,  0.1102,  0.0736,\n",
       "           -0.1080, -0.0440, -0.0526, -0.0030,  0.1028,  0.0584,  0.0621,\n",
       "           -0.0550,  0.0381,  0.0302,  0.0928, -0.1148,  0.0194, -0.0691,\n",
       "           -0.0810, -0.0981, -0.1099,  0.1043, -0.1049,  0.0082,  0.0879,\n",
       "            0.0600,  0.0133, -0.0823,  0.0305,  0.0711,  0.0133, -0.0357,\n",
       "            0.0735, -0.0318, -0.0073, -0.0181,  0.0095, -0.0983, -0.0368,\n",
       "           -0.0154,  0.0387]]]),\n",
       " tensor([[[ 0.2252, -0.1287, -0.0025, -0.0167,  0.0594, -0.0098,  0.0946,\n",
       "           -0.1232,  0.1620,  0.0633,  0.1283,  0.1550,  0.0132,  0.1473,\n",
       "           -0.0216, -0.0117, -0.0480, -0.1835,  0.0978,  0.2136, -0.0924,\n",
       "           -0.0598, -0.1479, -0.0936,  0.0854,  0.1976, -0.1755, -0.0117,\n",
       "           -0.1637, -0.1475, -0.0681, -0.0300,  0.0255,  0.0628, -0.1405,\n",
       "           -0.1079, -0.1856, -0.0462,  0.0062, -0.0189, -0.0678,  0.0652,\n",
       "           -0.0733,  0.0091,  0.0480, -0.1362,  0.1465, -0.0538,  0.1951,\n",
       "            0.0389, -0.0495,  0.0939,  0.0560,  0.0211,  0.1033, -0.1608,\n",
       "            0.1843, -0.1139, -0.0763,  0.0238,  0.1030,  0.2218,  0.1356,\n",
       "           -0.2353, -0.0885, -0.1064, -0.0069,  0.2109,  0.1157,  0.1091,\n",
       "           -0.1260,  0.0708,  0.0531,  0.1626, -0.2070,  0.0378, -0.1275,\n",
       "           -0.1659, -0.1937, -0.2285,  0.2200, -0.2222,  0.0203,  0.1719,\n",
       "            0.1161,  0.0259, -0.1574,  0.0675,  0.1495,  0.0272, -0.0809,\n",
       "            0.1598, -0.0585, -0.0123, -0.0381,  0.0221, -0.1769, -0.0760,\n",
       "           -0.0295,  0.0807]]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(i.detach() for i in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (vanilla)",
   "language": "python",
   "name": "vanilla"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
