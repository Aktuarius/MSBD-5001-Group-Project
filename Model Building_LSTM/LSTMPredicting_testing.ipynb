{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "import re\n",
    "from readprocess import readprocess\n",
    "from NNfunctionality import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_path = Path(Path.cwd(),\"..\",\"ProcessedHistograms\").resolve()\n",
    "yield_path = Path(Path.cwd(),\"..\",\"Yield Data\",\"all_country_crop_yield_tons_per_hectare.csv\").resolve()\n",
    "water_path = Path(Path.cwd(),\"..\",\"WaterProcessed\").resolve()\n",
    "data_class = readprocess(featurepath=hist_path,yieldpath=yield_path,waterpath = water_path,train_yearcount=13,test_yearcount=1,num_timesteps=46,num_features=576)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the first 13 years for training. Final year for predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "water_array_train = data_class.water_array_train.reshape((-1,1))\n",
    "water_array_test = data_class.water_array_test.reshape((-1,1))\n",
    "scaler.fit(water_array_train)\n",
    "water_array_train = scaler.transform(water_array_train).reshape((len(data_class.country_list)*13,))\n",
    "water_array_test = scaler.transform(water_array_test).reshape((len(data_class.country_list)*1,))\n",
    "X_train = data_class.dataset_train_resized\n",
    "y_train = data_class.yield_array_train\n",
    "X_test = data_class.dataset_test_resized\n",
    "y_test = data_class.yield_array_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature data batches will be of shape 14,46,576 and yield will be of shape 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = prepare_dataset(X_train,water_array_train,y_train)\n",
    "dataloader_train = DataLoader(dataset_train,batch_size=1,shuffle=False,batch_sampler=None)\n",
    "dataset_test = prepare_dataset(X_test,water_array_test,y_test)\n",
    "dataloader_test = DataLoader(dataset_test,batch_size=1,shuffle=False,batch_sampler=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "#parameters to investigate\n",
    "hidden_units = [100,150]\n",
    "dense_units = [200,250]\n",
    "dropout = [0.2,0.25]\n",
    "\n",
    "combinations = list(product([i for i,j in enumerate(hidden_units)], [i for i,j in enumerate(dense_units)],[i for i,j in enumerate(dropout)]))\n",
    "parameter_list = list()\n",
    "\n",
    "for combination in combinations:\n",
    "    parameter_list.append([hidden_units[combination[0]],dense_units[combination[1]],dropout[combination[2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pasindu.Samaranayake\\Desktop\\MSc\\MSBD 5001\\EarthEngine\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 24]' is invalid for input of size 1472",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Pasindu.Samaranayake\\Desktop\\MSc\\MSBD 5001\\EarthEngine\\Code\\LSTMPredicting_testing.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/LSTMPredicting_testing.ipynb#ch0000039?line=9'>10</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(),lr \u001b[39m=\u001b[39m \u001b[39m0.001\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/LSTMPredicting_testing.ipynb#ch0000039?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch_no):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/LSTMPredicting_testing.ipynb#ch0000039?line=11'>12</a>\u001b[0m     trainvalidate\u001b[39m.\u001b[39;49mtrain(dataloader\u001b[39m=\u001b[39;49mdataloader_train,model\u001b[39m=\u001b[39;49mmodel,loss_fn\u001b[39m=\u001b[39;49mmse_loss,optimizer \u001b[39m=\u001b[39;49m optimizer,batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/LSTMPredicting_testing.ipynb#ch0000039?line=13'>14</a>\u001b[0m avg_error_valid,model \u001b[39m=\u001b[39m trainvalidate\u001b[39m.\u001b[39mvalidate(dataloader\u001b[39m=\u001b[39mdataloader_test,model \u001b[39m=\u001b[39m model,batch_size \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/LSTMPredicting_testing.ipynb#ch0000039?line=14'>15</a>\u001b[0m avg_error_train,model \u001b[39m=\u001b[39m trainvalidate\u001b[39m.\u001b[39mvalidate(dataloader\u001b[39m=\u001b[39mdataloader_train,model \u001b[39m=\u001b[39m model,batch_size \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Pasindu.Samaranayake\\Desktop\\MSc\\MSBD 5001\\EarthEngine\\Code\\NNfunctionality.py:140\u001b[0m, in \u001b[0;36mTrainingValidatingLSTM.train\u001b[1;34m(self, dataloader, model, loss_fn, optimizer, batch_size)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/NNfunctionality.py?line=136'>137</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch,(X1,X2,y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m    <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/NNfunctionality.py?line=137'>138</a>\u001b[0m     \u001b[39m#hidden state is instantiated at the beginning as the hidden state is not a learn parameter\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/NNfunctionality.py?line=138'>139</a>\u001b[0m     hidden_state \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39minit_hidden(batch_size)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/NNfunctionality.py?line=139'>140</a>\u001b[0m     yield_pred,hidden_state \u001b[39m=\u001b[39m model(X1,X2,hidden_state)\n\u001b[0;32m    <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/NNfunctionality.py?line=140'>141</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(yield_pred,y)\n\u001b[0;32m    <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/NNfunctionality.py?line=141'>142</a>\u001b[0m     model\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\Desktop\\MSc\\MSBD 5001\\EarthEngine\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Pasindu.Samaranayake\\Desktop\\MSc\\MSBD 5001\\EarthEngine\\Code\\NNfunctionality.py:104\u001b[0m, in \u001b[0;36mLSTMnetwork.forward\u001b[1;34m(self, x1, x2, h)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/NNfunctionality.py?line=93'>94</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x1,x2,h):\n\u001b[0;32m     <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/NNfunctionality.py?line=94'>95</a>\u001b[0m     \u001b[39m#https://discuss.pytorch.org/t/initialization-of-first-hidden-state-in-lstm-and-truncated-bptt/58384\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/NNfunctionality.py?line=95'>96</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/NNfunctionality.py?line=101'>102</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/NNfunctionality.py?line=102'>103</a>\u001b[0m     \u001b[39m#as pytorch only applies drop out if there are 2 stacked layers, we use a hacky way of unrolling the LSTM to apply dropout at each transition\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/NNfunctionality.py?line=103'>104</a>\u001b[0m     \u001b[39mfor\u001b[39;00m xt \u001b[39min\u001b[39;00m x1\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_size):\n\u001b[0;32m    <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/NNfunctionality.py?line=104'>105</a>\u001b[0m         lstm_output1,h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm_layer(xt,h)\n\u001b[0;32m    <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/NNfunctionality.py?line=105'>106</a>\u001b[0m     \u001b[39m#Reshape from (num sequences, batch size, neuron_num) to (num sequences * batch size, neuron_num)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Pasindu.Samaranayake/Desktop/MSc/MSBD%205001/EarthEngine/Code/NNfunctionality.py?line=106'>107</a>\u001b[0m     \u001b[39m# last_output = lstm_output1.contiguous().view(-1,self.hidden_size)[self.time_steps-1::self.time_steps,]\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[-1, 24]' is invalid for input of size 1472"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "for parameter_set in parameter_list:\n",
    "    epoch_no = 10\n",
    "    hidden_units = parameter_set[0]\n",
    "    dense_units = parameter_set[1]\n",
    "    dropout = parameter_set[2]\n",
    "    trainvalidate = TrainingValidatingLSTM()\n",
    "    model = LSTMnetwork(32,hidden_dim = hidden_units,dense_size = dense_units,batch_size = 1,extra_features = 1,dropout = dropout,time_steps=46)\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr = 0.001)\n",
    "    for i in range(epoch_no):\n",
    "        trainvalidate.train(dataloader=dataloader_train,model=model,loss_fn=mse_loss,optimizer = optimizer,batch_size=1)\n",
    "\n",
    "    avg_error_valid,model = trainvalidate.validate(dataloader=dataloader_test,model = model,batch_size =1)\n",
    "    avg_error_train,model = trainvalidate.validate(dataloader=dataloader_train,model = model,batch_size =1)\n",
    "    print(avg_error_valid,avg_error_train)\n",
    "    results_dict[f\"Hidden Units : {hidden_units},Dense Units : {dense_units}, Dropout : {dropout}\"] = (avg_error_valid,model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = results_dict[\"Hidden Units : 50,Dense Units : 250, Dropout : 0.25\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = results_dict['Hidden Units : 100,Dense Units : 250, Dropout : 0.5'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = list()\n",
    "truth = list()\n",
    "for batch,(X,y) in enumerate(dataloader_train):\n",
    "    hidden_state = best_model.init_hidden(14)\n",
    "    ypred,hidden_state = best_model(X,hidden_state)\n",
    "    ypred = list(ypred.reshape(y.shape).detach().numpy())\n",
    "    pred_list.extend(ypred)\n",
    "    y = list(y.numpy())\n",
    "    truth.extend(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model with extra water feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pasindu.Samaranayake\\Desktop\\MSc\\MSBD 5001\\EarthEngine\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "C:\\Users\\Pasindu.Samaranayake\\Desktop\\MSc\\MSBD 5001\\EarthEngine\\lib\\site-packages\\torch\\nn\\modules\\loss.py:529: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "epoch_no = 10\n",
    "model_water = LSTMnetwork(576,hidden_dim=50,dense_size = 250,batch_size = 1,extra_features = 1,dropout = 0.25,time_steps=46)\n",
    "mse_loss = nn.MSELoss()\n",
    "trainvalidate = TrainingValidatingLSTM()\n",
    "optimizer = torch.optim.SGD(model_water.parameters(),lr = 0.001)\n",
    "for i in range(epoch_no):\n",
    "    trainvalidate.train(dataloader=dataloader_train,model=model_water,loss_fn=mse_loss,optimizer = optimizer,batch_size=1)\n",
    "avg_error,model_water = trainvalidate.validate(dataloader=dataloader_test,model = model_water,batch_size =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7351)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (vanilla)",
   "language": "python",
   "name": "vanilla"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
